{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cp data/Train_target.csv ./raw_data/Train_target.csv\n",
    "# ! cp data/Test_target.csv ./raw_data/Test_target.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"./data/Train.csv\")\n",
    "test=pd.read_csv(\"./data/Test.csv\")\n",
    "sample_sub=pd.read_csv(\"./data/sample_sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert features  fron string to List of values \n",
    "def replace_nan(x):\n",
    "    if x==\" \":\n",
    "        return np.nan\n",
    "    else :\n",
    "        return float(x)\n",
    "features=[\"temp\",\"precip\",\"rel_humidity\",\"wind_dir\",\"wind_spd\",\"atmos_press\"]\n",
    "for feature in features : \n",
    "    train[feature]=train[feature].apply(lambda x: [ replace_nan(X) for X in x.replace(\"nan\",\" \").split(\",\")])\n",
    "    test[feature]=test[feature].apply(lambda x: [ replace_nan(X)  for X in x.replace(\"nan\",\" \").split(\",\")])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(x,col_name):\n",
    "    x[\"max_\"+col_name]=x[col_name].apply(np.max)\n",
    "    x[\"min_\"+col_name]=x[col_name].apply(np.min)\n",
    "    x[\"mean_\"+col_name]=x[col_name].apply(np.mean)\n",
    "    x[\"std_\"+col_name]=x[col_name].apply(np.std)\n",
    "    x[\"var_\"+col_name]=x[col_name].apply(np.var)\n",
    "    x[\"median_\"+col_name]=x[col_name].apply(np.median)\n",
    "    x[\"ptp_\"+col_name]=x[col_name].apply(np.ptp)\n",
    "    return x  \n",
    "def remove_nan_values(x):\n",
    "    return [e for e in x if not math.isnan(e)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train,test],sort=False).reset_index(drop=True)\n",
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in tqdm(features):\n",
    "    data[col_name]=data[col_name].apply(remove_nan_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in tqdm(features):\n",
    "    data=aggregate_features(data,col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(121):\n",
    "    data[\"newtemp\"+ str(x)] = data.temp.str[x]\n",
    "    data[\"newprecip\"+ str(x)] = data.precip.str[x]\n",
    "    data[\"newrel_humidity\"+ str(x)] = data.rel_humidity.str[x]\n",
    "    data[\"newwind_dir\"+ str(x)] = data.wind_dir.str[x]\n",
    "    data[\"windspeed\"+ str(x)] = data.wind_spd.str[x]\n",
    "    data[\"atmospherepressure\"+ str(x)] = data.atmos_press.str[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(features,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data[data.target.notnull()].reset_index(drop=True)\n",
    "test=data[data.target.isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data  \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation strategy (Kfold,or simple train test split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment_name=\"simple_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"proc_data\", exist_ok=True)\n",
    "# os.makedirs(\"model_save/lgbm/{}\".format(Experiment_name), exist_ok=True)\n",
    "# os.makedirs(\"model_save/catboost/{}\".format(Experiment_name), exist_ok=True)\n",
    "# os.makedirs(\"model_save/xgboost/{}\".format(Experiment_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try : \n",
    "    folds=pd.read_csv(\"./proc_data/folds_id.csv\")\n",
    "    train=train.merge(folds,on=\"ID\",how=\"left\")\n",
    "    train.fold.nunique()\n",
    "except : \n",
    "    #  you run this cell  only for the first time \n",
    "    from sklearn.model_selection import KFold \n",
    "    kfold=KFold(n_splits=5,shuffle=True,random_state=2020) # change this random_state or all of you will have the same score  :D \n",
    "    train.reset_index(drop=True,inplace=True)\n",
    "    folds=train[[\"ID\"]].copy()\n",
    "    folds[\"fold\"]=0\n",
    "    for fold,(tr_indx,val_ind) in enumerate(kfold.split(folds)) : \n",
    "        folds.loc[val_ind,\"fold\"]=fold\n",
    "    folds.to_csv(\"./proc_data/folds_id.csv\",index=False)\n",
    "    train=train.merge(folds,on=\"ID\",how=\"left\")\n",
    "    \n",
    "    del folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name=\"target\"\n",
    "id_name=\"ID\"\n",
    "features_to_remove=[target_name,id_name,\"fold\",\"location\"]\n",
    "features=train.columns.tolist()\n",
    "features=[ fea for fea in  features if fea not in features_to_remove  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def metric(y,x):\n",
    "    return np.sqrt(mean_squared_error(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  lightgbm as lgbm \n",
    "# import xgboost as xgb \n",
    "# import catboost as cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(model,train,test,params,other_params,target_name,features,metric):\n",
    "    folds_num=train.fold.nunique()\n",
    "    validation=train[[id_name,\"fold\",target_name]].copy()\n",
    "    validation[\"pred_\"+target_name]=0\n",
    "    sub=test[[id_name]].copy()\n",
    "    sub[target_name]=0\n",
    "    for fold in np.sort(train.fold.unique()):\n",
    "        print(\"#\"*50+\" {} \".format(fold)+\"#\"*50)\n",
    "        os.makedirs(\"model_save/lgbm/{}/{}\".format(Experiment_name,str(int(fold))), exist_ok=True)\n",
    "        X_train=train[train.fold!=fold]\n",
    "        X_val=train[train.fold==fold]\n",
    "        \n",
    "        train_pred,validation_pred,test_pred=model(X_train,X_val,test,params,other_params)\n",
    "        \n",
    "        validation.loc[validation.fold==fold,\"pred_\"+target_name]=validation_pred\n",
    "        sub[target_name]+=test_pred/folds_num\n",
    "        train_score=metric(X_train[target_name],train_pred)\n",
    "        val_score=metric(X_val[target_name],validation_pred)\n",
    "        print(\"train score : {} validation score : {}\".format(round(train_score,4),round(val_score,4)))\n",
    "    final_validation_score=metric(validation[target_name],validation[\"pred_\"+target_name])\n",
    "    print(\"final validation score : {}\".format(final_validation_score))\n",
    "        \n",
    "    return sub,validation,final_validation_score\n",
    "\n",
    "def lgbm_model(X_train,X_val,X_test,params,other_params):\n",
    "    dtrain = lgbm.Dataset(data=X_train[features], label=X_train[target_name], feature_name=features)\n",
    "    dval = lgbm.Dataset(data=X_val[features], label=X_val[target_name], feature_name=features)\n",
    "\n",
    "    model = lgbm.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=other_params[\"num_boost_round\"],\n",
    "        valid_sets=(dtrain, dval),\n",
    "        early_stopping_rounds=other_params[\"early_stopping_rounds\"],\n",
    "        verbose_eval=other_params[\"verbose_eval\"],\n",
    "    )        \n",
    "    best_iteration = model.best_iteration\n",
    "    train_pred=model.predict(X_train[features], num_iteration=best_iteration)\n",
    "    validation_pred=model.predict(X_val[features], num_iteration=best_iteration)\n",
    "    test_pred=model.predict(test[features], num_iteration=best_iteration)\n",
    "        \n",
    "    return train_pred,validation_pred,test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_params={\"num_boost_round\":50000000,\n",
    "              \"early_stopping_rounds\":50,\n",
    "              \"verbose_eval\":1000,\n",
    "}\n",
    "lgbm_params = {\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 2,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_threads\": 16,\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"seed\": 2020,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub,validation,score=train_function(model=lgbm_model,\n",
    "                                    train=train,\n",
    "                                    test=test,\n",
    "                                    params=lgbm_params,\n",
    "                                    other_params=other_params,\n",
    "                                    target_name=target_name,\n",
    "                                    features=features,\n",
    "                                    metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"subs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"./subs/lgbm_{}.csv\".format(round(score,2)),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca9b09bbfd254199bc645f5c79a6882d566302db735db839fd7d76ed8e17467a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
