{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping of data and CSV exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retyping strings to lists for pd.explode() to work\n",
    "for c in data.columns[2:-1]:\n",
    "    data[c] = data[c].apply(lambda x: [a for a in str(x).split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating hours column counting from 0 to 120 (5 days with first day having 25 measurements)\n",
    "hours = list(range(121))\n",
    "\n",
    "# inserting column before target column\n",
    "data.insert(len(data.columns)-1, 'hours', [hours] * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating days column counting from 1 to 5 (first day having 25 measurements)\n",
    "day = [1, 2, 3, 4, 5]\n",
    "rep = [25, 24, 24, 24, 24]\n",
    "days = np.repeat(day, rep)\n",
    "\n",
    "# inserting column before target column\n",
    "data.insert(len(data.columns)-1, 'day', [days] * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the dataframe to convert from pseudo-wide to long format\n",
    "data = data.explode(data.columns[2:-1].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retype all values from string (was necessary for split) to float\n",
    "for c in data.columns[2:]:\n",
    "    data[c] = data[c].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the long dataframe as csv\n",
    "data.to_csv('data/train_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to further work with the data, replace all 'nan' strings with np.nan\n",
    "data = data.replace('nan', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate how many observations have missing data (%)\n",
    "np.round(data.isna().sum()/data.shape[0] * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check overlap of missing data\n",
    "msno.matrix(data, color=(0, 0, 0.33));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(data, group: list, cid: tuple, func: str) -> pd.DataFrame:\n",
    "    \"\"\"Returns one of [mean, median, min, max] for dataframe grouped by 'group'.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): _description_\n",
    "        group (list): column names by which to group by\n",
    "        cid (list): boundary column indices (left, right)\n",
    "        func (str): accepts mean, median, min, max\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "    \"\"\"\n",
    "    if func == 'mean':\n",
    "        return data.groupby(group)[data.columns[cid[0]:cid[1]]].mean()\n",
    "    elif func == 'median':\n",
    "        return data.groupby(group)[data.columns[cid[0]:cid[1]]].median()\n",
    "    elif func == 'min':\n",
    "        return data.groupby(group)[data.columns[cid[0]:cid[1]]].min()\n",
    "    elif func == 'max':\n",
    "        return data.groupby(group)[data.columns[cid[0]:cid[1]]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get different aggregates from the data and export as csv\n",
    "for i in ['mean', 'median', 'min', 'max']:\n",
    "    aggregate(data, ['ID', 'day'], (2,-3), i).to_csv(f'data/train_daily_{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca9b09bbfd254199bc645f5c79a6882d566302db735db839fd7d76ed8e17467a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
